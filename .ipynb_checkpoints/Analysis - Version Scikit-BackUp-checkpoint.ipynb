{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import math\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining the 13 CSVs of CEO Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os   #C:\\Users\\Bloody Dachi\\Documents\\CS_401\\Final_Project\\CEO-Topic-Classifier-Extractor\\Finished_Tweet_CSV\n",
    "path =r'C:/Users/Bloody Dachi/Documents/CS_401/Final_Project/CEO-Topic-Classifier-Extractor/Finished_Tweet_CSV' # use your path\n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "list_ = []\n",
    "\n",
    "for file_ in allFiles: \n",
    "    df = pd.read_csv(file_,index_col=None, encoding = \"latin1\",lineterminator='\\n')\n",
    "    list_.append(df)\n",
    "frame = pd.concat(list_, axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>CEO_Full_Name</th>\n",
       "      <th>CEO_User_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@pjournel The bag itself is from dsptch in San...</td>\n",
       "      <td>Phil Libin</td>\n",
       "      <td>plibin\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I MacGyvered extra storage pouches to my backp...</td>\n",
       "      <td>Phil Libin</td>\n",
       "      <td>plibin\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Snack times Nuts equals Snuts, people. Itâs ...</td>\n",
       "      <td>Phil Libin</td>\n",
       "      <td>plibin\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Looking forward to being back in Beijing this ...</td>\n",
       "      <td>Phil Libin</td>\n",
       "      <td>plibin\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>For better and for worse, but mostly for the b...</td>\n",
       "      <td>Phil Libin</td>\n",
       "      <td>plibin\\r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Tweet  \\\n",
       "0           0  @pjournel The bag itself is from dsptch in San...   \n",
       "1           1  I MacGyvered extra storage pouches to my backp...   \n",
       "2           2  Snack times Nuts equals Snuts, people. Itâs ...   \n",
       "3           3  Looking forward to being back in Beijing this ...   \n",
       "4           4  For better and for worse, but mostly for the b...   \n",
       "\n",
       "  CEO_Full_Name CEO_User_Name\\r  \n",
       "0    Phil Libin        plibin\\r  \n",
       "1    Phil Libin        plibin\\r  \n",
       "2    Phil Libin        plibin\\r  \n",
       "3    Phil Libin        plibin\\r  \n",
       "4    Phil Libin        plibin\\r  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frame = frame.drop(['Unnamed: 0'], axis=1)\n",
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "903277"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Multi-Index to reference Tweets of specific CEOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = [frame[\"CEO_Full_Name\"]]\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=['CEO_Names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEO_Names</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Phil Libin</th>\n",
       "      <td>@pjournel The bag itself is from dsptch in San...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phil Libin</th>\n",
       "      <td>I MacGyvered extra storage pouches to my backp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phil Libin</th>\n",
       "      <td>Snack times Nuts equals Snuts, people. Itâs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phil Libin</th>\n",
       "      <td>Looking forward to being back in Beijing this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phil Libin</th>\n",
       "      <td>For better and for worse, but mostly for the b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Tweets\n",
       "CEO_Names                                                    \n",
       "Phil Libin  @pjournel The bag itself is from dsptch in San...\n",
       "Phil Libin  I MacGyvered extra storage pouches to my backp...\n",
       "Phil Libin  Snack times Nuts equals Snuts, people. Itâs ...\n",
       "Phil Libin  Looking forward to being back in Beijing this ...\n",
       "Phil Libin  For better and for worse, but mostly for the b..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.DataFrame(list(frame[\"Tweet\"]), index=index, columns = [\"Tweets\"])\n",
    "(df_new).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Time to rebalance? RT @AccountingEdit: Manuel: When it comes to the economy â\\x80\\x93 buckle your seatbelts! #dcpa18',\n",
       "       'Agree! RT @mmaycpa: What a treat to have @AnjaManuel1 presenting at #DCPA18. Very informative presentation about tech, &amp; global players China, India.',\n",
       "       'RT @AccountingEdit: Manuel: If thereâ\\x80\\x99s an AI race between the U.S. and China, itâ\\x80\\x99s not at all clear whoâ\\x80\\x99s going to come out on top. #dcpa18',\n",
       "       ...,\n",
       "       'RT @maragoni: #FutureReady is for everyone. Non-financial #blockchain uses will touch everything from real estate to app development to diamond industry: @ronqman #DCPA17',\n",
       "       'Listening to @rmp289 of @ChristensenInst about how to think about disruption #dcpa17 https://t.co/XMO4WGHCT1',\n",
       "       'He was great and he is coming to Maryland next Weds to open our CPA Summit - https://t.co/VrZsHNI5Uv live and by webcast. #futureready https://t.co/Rs1pSciR5o'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.loc['Tom Hood']['Tweets'].values#.head()\n",
    "#Add[\"Tweets\"] in order to access the tweets of "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['nbcnews', 'this', 'is', 'completely', 'backwards', 'based', 'on', 'what', 'we', 've', 'learned', 'from', 'the', 'hawthorne', 'test', 'tunnel', 'we', 're', 'moving', 'forward', 'with', 'a', 'much', 'larger', 'tunnel', 'network', 'under', 'la', 'won', 't', 'need', 'a', 'second', 'test', 'tunnel', 'under', 'sepulveda'], ['you', 'can', 'summon', 'your', 'tesla', 'from', 'your', 'phone', 'only', 'short', 'distances', 'today', 'but', 'in', 'a', 'few', 'years', 'summon', 'will', 'work', 'from', 'across', 'the', 'continent', 'https', 't', 'co', 'xcj67ajz8h'], ['cool', 'actually', 'if', 'you', 'buy', 'a', 'tesla', 'without', 'a', 'test', 'drive', 'you', 'have', '3', 'days', 'to', 'return', 'it', 'if', 'you', 'buy', 'after', 'a', 'test', 'drive', 'you', 'still', 'have', '24', 'hours', 'trying', 'to', 'incent', 'buying', 'with', 'no', 'test', 'drive', 'https', 't', 'co', 'o2dd5bgxrz']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "token_words = []\n",
    "for i in df_new.loc['Elon Musk']['Tweets'].values:\n",
    "    raw = i.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    token_words.append(tokens)\n",
    "    \n",
    "    #tokens = tokenizer.tokenize(token_words)\n",
    "print(token_words[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmzatizing and Stemming of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    texts = [p_stemmer.stem(i) for i in stop_free]\n",
    "    punc_free = ''.join(ch for ch in texts if ch not in exclude)\n",
    "    \n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n",
    "doc_clean = [clean(doc).split() for doc in df_new.loc['Elon Musk']['Tweets'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['nbcnews', 'completely', 'backwards', 'based', 'we\\x92ve', 'learned', 'hawthorne', 'test', 'tunnel', 'we\\x92re', 'moving', 'forward', 'much', 'larger', 'tunnel', 'network', 'la', 'won\\x92t', 'need', 'second', 'test', 'tunnel', 'sepulveda'], ['summon', 'tesla', 'phone', 'short', 'distance', 'today', 'year', 'summon', 'work', 'across', 'continent', 'httpstcoxcj67ajz8h'], ['cool', 'actually', 'buy', 'tesla', 'without', 'test', 'drive', '3', 'day', 'return', 'it', 'buy', 'test', 'drive', 'still', '24', 'hour', 'trying', 'incent', 'buying', 'test', 'drive', 'httpstcoo2dd5bgxrz']]\n"
     ]
    }
   ],
   "source": [
    "print(doc_clean[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nbcnews',\n",
       " 'completely',\n",
       " 'backwards',\n",
       " 'based',\n",
       " 'we\\x92ve',\n",
       " 'learned',\n",
       " 'hawthorne',\n",
       " 'test',\n",
       " 'tunnel',\n",
       " 'we\\x92re',\n",
       " 'moving',\n",
       " 'forward',\n",
       " 'much',\n",
       " 'larger',\n",
       " 'tunnel',\n",
       " 'network',\n",
       " 'la',\n",
       " 'won\\x92t',\n",
       " 'need',\n",
       " 'second',\n",
       " 'test',\n",
       " 'tunnel',\n",
       " 'sepulveda']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_clean[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791\n"
     ]
    }
   ],
   "source": [
    "print(len(df_new.loc['Elon Musk']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phil Libin\n",
      "Tom Hood\n",
      "Lauren Cook\n",
      "Joni Thomas Doolin\n",
      "Sundar Pichai\n",
      "Don Tapscott\n",
      "Alexander Torrenegra\n",
      "Drazen Drazic\n",
      "Roger Toennis\n",
      "Michal MeÅ¡ko\n",
      "Doug Wick\n",
      "Seth Besmertnik\n",
      "Michael Ferrari\n",
      "Benjamin Ellis\n",
      "Larry Freed\n",
      "Julian Treasure\n",
      "Michael Friedenberg\n",
      "Joel Strellner\n",
      "Joshua March\n",
      "Dan Neely\n",
      "Nate Weiner\n",
      "Rick Myers\n",
      "jennifer evans\n",
      "Brian Chesky\n",
      "Kyle Lacy\n",
      "Russell Fradin\n",
      "Mark O'Brien\n",
      "Tony Uphoff\n",
      "Nilofer Merchant\n",
      "Dan Kimerling\n",
      "Robin Chase\n",
      "Laura Bennett\n",
      "tomgerace\n",
      "Daniel Ek\n",
      "Vanessa DiMauro\n",
      "Jules Pieri\n",
      "Mom Central\n",
      "Pierre-Loic Assayag\n",
      "Matt Hunt\n",
      "Dave Kerpen\n",
      "kellyhadous\n",
      "Zvi Band\n",
      "Ethan Bloch\n",
      "Kara Goldin ð\n",
      "Mark Josephson\n",
      "jasongorham\n",
      "Shama Hyder\n",
      "Nate Riggs\n",
      "Brandon Evans\n",
      "Matt Lovett\n",
      "Seamus\n",
      "Brian Carroll\n",
      "Barry Libert\n",
      "Tom H C Anderson\n",
      "deb lavoy\n",
      "travis kalanick\n",
      "Jim Stewart\n",
      "David Feldt\n",
      "Christine Perkett\n",
      "Marcel LeBrun\n",
      "devahaz\n",
      "Panos Kontopoulos\n",
      "Bernie Borges\n",
      "Aaron Dignan\n",
      "Oscar Berg\n",
      "Deirdre Breakenridge\n",
      "Rob May\n",
      "Paul Helmick\n",
      "Guy Kawasaki\n",
      "Chris Cera\n",
      "Melanie Notkin\n",
      "Richard Branson\n",
      "Kevin O'Keefe\n",
      "Mark Ghuneim\n",
      "Krista Neher\n",
      "Dave Elchoness\n",
      "Adam Lavelle\n",
      "Small Business Trends\n",
      "Gerd Leonhard\n",
      "Sam Lawrence\n",
      "Jeff Dachis\n",
      "Sam Flemming\n",
      "Axel Schultze\n",
      "Nova Spivack\n",
      "Josh McHugh\n",
      "Zappos.com\n",
      "Danielle Morrill\n",
      "Kathleen Hessert\n",
      "Jordan Ayan\n",
      "Mark Ragan\n",
      "Eduardo Croissier\n",
      "Steve Case\n",
      "Jason Heller\n",
      "Mark Kingdon\n",
      "Deena Varshavskaya\n",
      "Tony Haile\n",
      "CÃ©dric Giorgi\n",
      "Matt Van Horn\n",
      "Wences Casares\n",
      "Todd Vernon\n",
      "Aaron Newman\n",
      "Richard Laermer\n",
      "Craig Swerdloff\n",
      "Muhammad Saleem\n",
      "Nancy Hill\n",
      "Jim Bankoff\n",
      "keith parnell\n",
      "Jeff Hilimire\n",
      "Duncan Alney\n",
      "michael lazerow\n",
      "Diane Hessan\n",
      "Jess Lee\n",
      "Tom Preston-Werner\n",
      "Jesse Stay\n",
      "Levi Brooks\n",
      "Toby Daniels\n",
      "Yoav Lurie\n",
      "Jamie Riddell\n",
      "Patrick Collison\n",
      "Ryan Singel\n",
      "Ingrid Alongi\n",
      "Robert Dempsey\n",
      "T.A. McCann\n",
      "Jesse Middleton\n",
      "Tucker Max\n",
      "Chamath Palihapitiya\n",
      "Joe Fernandez\n",
      "Jay Adelson\n",
      "Jim Louderback\n",
      "Tim O'Reilly\n",
      "Kevin Lane Skarritt\n",
      "Alex Iskold ð½\n",
      "Jason Alba\n",
      "Daniel Ha\n",
      "Martin Perron\n",
      "Cotter Cunningham\n",
      "Steven Krein\n",
      "Sara Holoubek\n",
      "Timothy Young\n",
      "Ed Illig\n",
      "Timothy Rowe\n",
      "Eugene Lee\n",
      "Nat Turner\n",
      "Amanda Vega\n",
      "David Marcus\n",
      "Wendy Piersall â\n",
      "David Sacks\n",
      "Ian Schafer\n",
      "David Sifry\n",
      "Scott Monty\n",
      "Aaron Levie\n",
      "Mukund Mohan\n",
      "Jonah Peretti\n",
      "Joseph Thornley\n",
      "John Eckman\n",
      "Kris Duggan\n",
      "Chris Kalaboukis\n",
      "Paul McEnany\n",
      "Frank Gruber\n",
      "Stuart MacDonald\n",
      "Marshall Kirkpatrick\n",
      "David Cohen\n",
      "Alfonso Guerra\n",
      "Jeremy Wright\n",
      "gianandrea facchini\n",
      "Sally Strebel\n",
      "Ari Paparo\n",
      "Tony Wright\n",
      "zach sims\n",
      "Charlie O'Donnell\n",
      "John Lilly\n",
      "Carolyn Rafaelian\n",
      "Loic Le Meur ð\n",
      "G.\n",
      "Todd Defren\n",
      "Kevin Rose â©\n",
      "Chad Dickerson\n",
      "Andy Budd in New York\n",
      "Anil Dash ð¥­\n",
      "Ryan Carson\n",
      "Matt Mullenweg\n",
      "Auren Hoffman\n",
      "Chris Heuer\n",
      "David Cancel\n",
      "Pat\n",
      "Brian Clark\n",
      "Reid Hoffman\n",
      "Zachary Rosen\n",
      "Paul Farnell\n",
      "Stephen Randall\n",
      "Elliott Ng\n",
      "John Borthwick\n",
      "jason ð¦ð¦ð¦ð¦ð¦ð¦\n",
      "BJ Cook\n",
      "Oren Michels\n",
      "Adam Rifkin ð¼\n",
      "Jake Nickell\n",
      "Scott Heiferman\n",
      "Jeffrey Veen\n",
      "Ev Williams\n",
      "jack\n",
      "Judy Monroe, MD\n",
      "Jill Storey\n",
      "David Franklin, USN\n",
      "Paul Polman\n",
      "Ken Lingad\n",
      "Jonathan O'Byrne\n",
      "Tony Duffin\n",
      "Eleanor Allen\n",
      "Dawn Zier\n",
      "Donna Griffit\n",
      "Marcus Allen\n",
      "Victoria Espinel\n",
      "Brandon Edwards\n",
      "Brian A Russell\n",
      "Tamara McCleary\n",
      "Ben Watts\n",
      "Sujay R Jadhav\n",
      "Balaji S. Srinivasan\n",
      "Patrick Byrne\n",
      "Kieran Goodwin\n",
      "Adam Greenbaum\n",
      "Kathy Calvin\n",
      "John Legere\n",
      "Hani Farsi\n",
      "Julian David\n",
      "Morgan Berman\n",
      "Jane Miller\n",
      "Andrew Limouris\n",
      "Monique Villa\n",
      "Louis Del Monte\n",
      "AQ\n",
      "Carolyn Hardy\n",
      "Lizelle van Vuuren\n",
      "Anthony Ferrier\n",
      "I. Dolly Lenz\n",
      "Ellen Agler\n",
      "Jane Chen\n",
      "Carrie Mantha\n",
      "Terri Seese\n",
      "Scott Petinga\n",
      "Debra Jacobs\n",
      "Zen Yinger\n",
      "Brook Parker Bello PH.D\n",
      "Nick Stanhope\n",
      "Bill Nuti\n",
      "Katryna Dow ?\n",
      "Yael Lehmann\n",
      "Zack Kanter\n",
      "Rachel Gerrol\n",
      "Dr. Timothy C. Summers\n",
      "Gregory Bailey\n",
      "Keith Wakeman\n",
      "Bob Ruffolo\n",
      "Sylvain Bernolle\n",
      "Matt Law\n",
      "Dr. Sue Desmond-Hellmann\n",
      "Dr. Waleed Al-Salem\n",
      "Joaquin Roca\n",
      "Gabrielle Fitzgerald\n",
      "Hunter Johnson\n",
      "Leslee Thompson\n",
      "Nicholas Hill\n",
      "Da\\/id Hallett CEO ?\n",
      "Matt Dykstra\n",
      "Carine Clark, CEO\n",
      "Sue Todd\n",
      "Jennilee Peremore\n",
      "John Hall\n",
      "Bryan Adams\n",
      "Angela Blanchard\n",
      "Rob Legge\n",
      "Kieran Snyder\n",
      "Christine Kurban\n",
      "Chris Arnold\n",
      "Karim Abouelnaga\n",
      "Jeremy Galbraith\n",
      "Michael Young\n",
      "Lisa Bodell\n",
      "Tim Masson\n",
      "Nina Nashif\n",
      "Jo Ann Jenkins\n",
      "Jason Saltzman\n",
      "Jennifer Siebel Newsom\n",
      "Darin McKeever\n",
      "Jennifer Brandel\n",
      "Antony Bugg-Levine\n",
      "Jen Durkin\n",
      "Vikki Spruill\n",
      "Kurt Carlson\n",
      "Cooper Pickett\n",
      "Anne Boden\n",
      "ernesto schmitt\n",
      "David Fox\n",
      "Scott McNealy\n",
      "Ralph Capocci ??\n",
      "David Dabscheck\n",
      "Doug Conant\n",
      "Matt Johnston\n",
      "Bob Moul\n",
      "Michael Saylor\n",
      "Jim VandeHei\n",
      "Dr Sally Uren\n",
      "Devin Wenig\n",
      "Denise Hamilton\n",
      "Daniel Newman\n",
      "Becky Robinson\n",
      "Josep Soldevila\n",
      "Scott Levy\n",
      "Andy Dunn\n",
      "Tim Fargo ?\n",
      "Jennifer Hyman\n",
      "Michael Overell\n",
      "Vikas Khemani\n",
      "Brendan Wallace\n",
      "Aaron Hurst\n",
      "Rebecca Harrison\n",
      "Anthony Goldbloom\n",
      "Rachel Shechtman\n",
      "Jason Cyr\n",
      "Phil Fremont-Smith\n",
      "Gary Haugen\n",
      "Claire Lew\n",
      "jorn lyseggen\n",
      "Milind Bhandarkar\n",
      "Sravish Sridhar\n",
      "Bob Ottenhoff\n",
      "Bryan Wempen\n",
      "Deborah B Jackson\n",
      "Guillaume ROUSSEAU\n",
      "Lean Leader\n",
      "Paul Mosenson\n",
      "Marcus Shingles\n",
      "Derrick Hall\n",
      "Jacki Zehner\n",
      "ronan le moal\n",
      "Garry Ridge\n",
      "Ananth V\n",
      "Judy Hamilton\n",
      "Mike Kawula ???\n",
      "Jonathan Sackett\n",
      "Bob Collymore\n",
      "Jen Fremont-Smith\n",
      "Paul Thorndike\n",
      "Michael Lenczner\n",
      "Krista Marks\n",
      "Joan Mulvihill\n",
      "Yusuf  Azizullah\n",
      "????? H. Mikitani\n",
      "Jennifer Lockwood-Sh\n",
      "Nick Bayer\n",
      "Jake Dunlap\n",
      "Ned Breslin\n",
      "Denise Terry\n",
      "David Biemesderfer\n",
      "Jean-Marc Lazard\n",
      "David Miliband\n",
      "Jack Salzwedel\n",
      "Howie Goldfarb\n",
      "Rick Perreault\n",
      "Mark T. Bertolini\n",
      "John Laramie\n",
      "Srinivas Rao\n",
      "Francesco Baschieri\n",
      "Jason Goldberg v0.1\n",
      "Andrea Goulet\n",
      "Bill George\n",
      "Nicolas Dessaigne\n",
      "Andy Kurtzig\n",
      "Michael Dell\n",
      "Jeremy Heimans\n",
      "Kristof De Wulf\n",
      "Khadim Hussain\n",
      "Rehman Siddiq\n",
      "Lucio  Chiappa [°I°]\n",
      "Michael E. Parker\n",
      "Robert L. Reynolds\n",
      "Dror Pockard\n",
      "Adam Quinton\n",
      "Nate DaPore\n",
      "Noland Hoshino\n",
      "Apu Gupta\n",
      "Laura Petrolino\n",
      "Brent Beshore\n",
      "Greg Jaros\n",
      "Elon Musk\n",
      "Joshua H. Davidson\n",
      "Tanya Hall\n",
      "Lexie Norcross\n",
      "Todd Graves\n",
      "TheresaB\n",
      "Diana V. Carriço\n",
      "Dan T. Cathy\n",
      "Kristin Hull, PhD\n",
      "Craig Wortmann\n",
      "Marianne Caroline\n",
      "Walter Isaacson\n",
      "Miles S. Nadal\n",
      "Kamal Hotchandani\n",
      "Jeff Joerres\n",
      "Franck Ohrel\n",
      "Eric Schiffer\n",
      "Tom Cannon\n",
      "Fred Cuellar\n",
      "Dave Power\n",
      "Anita Grover\n",
      "Stephen Klasko\n",
      "Bob Moore\n",
      "Simon Mainwaring\n",
      "Joshua Miller\n",
      "Terena Bell\n",
      "Delbourg-Delphis\n",
      "Emily Miethner ð¥ #FindSpark  #HustleSummit\n",
      "Bill Simmel\n",
      "Aaron Epstein\n",
      "Michael Chatman\n",
      "Justin Wisz\n",
      "Jim O'Shaughnessy\n",
      "Lucy P. Marcus\n",
      "Robert U Craven\n",
      "Jacob Harold\n",
      "Nicole Watson\n",
      "Ronn Torossian\n",
      "Craig Powell\n",
      "Soledad O'Brien\n",
      "Jim Weiss\n",
      "Shannon Thomas-Steffen\n",
      "Luis Rasquilha\n",
      "SKORA Running\n",
      "tweetorit\n",
      "Tod Sacerdoti\n",
      "Norman Hebert\n",
      "Heather Marie\n",
      "Tim Hockey\n",
      "Abed Shaheen\n",
      "Surina Khan\n",
      "Jon Oringer\n",
      "Michael Lebowitz\n",
      "Gordon Makryllos\n",
      "Jason Chicola\n",
      "Michael Derins\n",
      "Meghan M. Biro â¡ï¸\n",
      "Downtown Josh Brown\n",
      "Marc Benioff\n",
      "Michael Gellman\n",
      "Raul Leal\n",
      "Mark Murrison\n",
      "VictorSanchezBarrera\n",
      "Arianna Huffington\n",
      "Gregg Croteau\n",
      "Lisa Wehr\n",
      "Rodney Schwartz\n",
      "Alex Yoder\n",
      "Max Lenderman\n",
      "Clint Greenleaf\n",
      "Anthony King\n",
      "Justyn Howard\n",
      "Miss Internet\n",
      "Å imon VostrÃ½\n",
      "Jason Rosenthal\n",
      "Alex Goldfayn\n",
      "Jacqueline Novogratz\n",
      "Tim Dybvig\n",
      "Dave Girouard\n",
      "Russ Mann\n",
      "Marissa Levin, CEO\n",
      "Bob Parsons\n",
      "Jeff Weiner\n",
      "Phil Jaurigue\n",
      "Robin Low\n",
      "Dinis Guarda\n",
      "Toby LaVigne\n",
      "Tanveer Naseer\n",
      "Jim Lanzone\n",
      "Jayson DeMers\n",
      "Lydia Chicles\n",
      "J'Amy Stewart\n",
      "Dan Berger\n",
      "Bob Jeffrey\n",
      "Lisa Reeves\n",
      "Tiffany Jana\n",
      "Christian Lisogorsky\n",
      "TinaSharkey\n",
      "Jack Conte\n",
      "Riitta Raesmaa-Aukia\n",
      "David Suydam\n",
      "mark hughes\n",
      "Ken Kay\n",
      "Shelly Kramer\n",
      "Trent Ricker\n",
      "arijacoby\n",
      "âµKim Walsh-Phillipsâµ\n",
      "Jeff Lanctot\n",
      "Jordy Leiser\n",
      "Dean Newlund\n",
      "Samir Arora /:-)\n",
      "Mike Astringer\n",
      "Paul Teshima\n",
      "Gini Dietrich\n",
      "Josh Allan Dykstra\n",
      "Nicole Casanova\n",
      "Debra Ruh\n",
      "Cybele Negris\n",
      "Rob Tarkoff\n",
      "Jean Case\n",
      "Andy Carroll\n",
      "Bruce Peters\n",
      "Noah Glass\n",
      "Paul Levy\n",
      "Chris Anderson\n",
      "Tony Schwartz\n",
      "Adam Needles\n",
      "marissamayer\n",
      "Mireille Ryan\n",
      "Ingrid Vanderveldt\n",
      "John Gerzema\n",
      "Nathan Kontny\n",
      "Insider Perks\n",
      "Jordan Kretchmer\n",
      "Tami McCarthy\n",
      "Shira Abel\n",
      "justindillon\n",
      "Richard Levick\n",
      "Paul Barron\n",
      "Andy Schornack\n",
      "bigwags\n",
      "Curatti\n",
      "Chuck Robbins\n",
      "Natty Zola\n",
      "Bill Pollak\n",
      "Andrea Meyer\n",
      "Marie Forleo\n",
      "Aaron Hall\n",
      "Jeff Booth\n",
      "Cali Williams Yost\n",
      "Jack Hadley\n",
      "Amy Jo Martin\n",
      "Pano Anthos\n",
      "carrie kerpen\n",
      "Jim Lundy\n",
      "Mark Cuban\n",
      "John J Peebles\n",
      "Doug Ulman\n",
      "Brian J. Dunn\n",
      "Dr. Ayesha Khanna\n",
      "Ed Scanlan\n",
      "Matt Hixson\n",
      "Joel Spolsky\n",
      "Brett Hurt\n",
      "Thom Rainer\n",
      "Scott Harrison\n",
      "BrandCrowd\n",
      "Julia Hartz\n",
      "Brad Hargreaves\n",
      "brianshin\n",
      "Jon MacDonald\n",
      "Richard Rosenblatt\n",
      "David Adler, BizBash\n",
      "Rob Peters\n",
      "fspeiser\n",
      "Simon Harrow\n",
      "Rafat Ali Ø±ÙØ¹Øª\n",
      "Joe Koufman\n",
      "Gay Gaddis\n",
      "Robert Vandenberg\n",
      "Drew Neisser - Chief Marketing Renegade\n",
      "Faun deHenry\n",
      "Rob Schwartz\n",
      "Jon Radoff\n",
      "Sam Decker\n",
      "Tereza Nemessanyi\n",
      "Tina Hui\n",
      "Tom Bedecarre\n",
      "Sue Marks\n",
      "Rajeev Singh\n",
      "Jon Ferrara\n",
      "Randall Rothenberg\n",
      "Albert ArnÃ³\n",
      "Rebecca Rivera\n",
      "Steve Cunningham\n",
      "Joanna Pineda\n",
      "Wayne Elsey\n",
      "John Ellett\n",
      "Gary Lee\n",
      "Dave Balter\n",
      "Carrie Silver-Stock\n",
      "Reid Carr\n",
      "Jack Barrette\n",
      "Brian Halligan\n",
      "Olin Hyde\n",
      "Adam J. Kovitz\n",
      "Lisa Qualls\n",
      "Padmasree\n",
      "Rachel Haot\n",
      "Linda Cureton\n",
      "Sam Shank\n",
      "BIGGBY BOB\n",
      "jamyn\n",
      "lalinda\n",
      "cliffprior\n",
      "Melinda Travis\n",
      "Rajiv Parikh\n",
      "Adam Q. Holden-Bache\n",
      "Matt Kaness\n",
      "Kathy Simmons\n",
      "Jeff Mignon\n",
      "Dr. Janice Presser\n",
      "Kim Patrick Kobza\n",
      "Nancy Duarte\n",
      "Mark Organ\n",
      "daynagrayson\n",
      "Clate Mask\n",
      "Jeff Lawson\n",
      "Amanda Hite\n",
      "Gina Schreck\n",
      "John Battelle\n",
      "Cal McAllister\n",
      "R Ray Wang (ççå",
      ") #My31\n",
      "Alex Moore ð§\n",
      "Brian Wong\n",
      "Marianne O'Connor\n",
      "Matt Salzberg\n",
      "Marieme Jamme\n",
      "Hollis Thomases\n",
      "Mike Ford\n",
      "Jeremy Toeman\n",
      "Joel Dehlin\n",
      "Brian Armstrong\n",
      "Jacquelyn Cyr\n",
      "kelkelly\n",
      "Rachel Levy\n",
      "Cassandra Bailey\n",
      "Kristina Halvorson\n",
      "Michael Hyatt\n",
      "Steve Goldstein\n",
      "Ramit Sethi\n",
      "scotwingo\n",
      "Helen Todd\n",
      "Kira Wampler\n",
      "Jason Kintzler\n",
      "Jason Keath\n",
      "Dwight Gibbs\n",
      "Peter Bordes\n",
      "Bob Pritchett\n",
      "Richard Jalichandra\n",
      "RobLane\n",
      "evÅk ad agency\n",
      "Jason Byrne\n"
     ]
    }
   ],
   "source": [
    "tweetDictionary = {}\n",
    "for i in df_new.index.unique():\n",
    "    tweetDictionary[i[0]] = df_new.loc[i[0]]['Tweets'].values\n",
    "for x in tweetDictionary:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_matrix(dic):\n",
    "    docs = dic\n",
    "    n = len(docs)\n",
    "    tf = {}\n",
    "    df = {}\n",
    "    length = {}\n",
    "    vocab = set()\n",
    "    for doc in docs:#list of names\n",
    "        tweets = docs[doc]\n",
    "        for i in range(len(tweets)):\n",
    "            if type(tweets[i]) == str:\n",
    "                words = nltk.word_tokenize(tweets[i])\n",
    "                words = [p_stemmer.stem(i) for i in words if i not in stop] #remove stopwords\n",
    "                words = [ch for ch in words if ch not in exclude]\n",
    "                length[doc] = 0\n",
    "                for word in words:\n",
    "                    if not word.isalpha():\n",
    "                        continue\n",
    "                    length[doc] += 1\n",
    "                    word = word.lower()\n",
    "                    vocab.add(word)\n",
    "                    if (word, doc) in tf:\n",
    "                        tf[word, doc] += 1\n",
    "                    else:\n",
    "                        tf[word, doc] = 1\n",
    "                    if word in df:\n",
    "                        df[word].add(doc)\n",
    "                    else:\n",
    "                        df[word] = set([doc])\n",
    "\n",
    "    tf_idf = {}\n",
    "    for word, doc in tf:\n",
    "        tf_idf[word, doc] = (tf[word, doc] / length[doc]) * math.log(n / len(df[word]), 10)\n",
    "        #tf_idf[word, doc] = (1 + math.log(tf[word, doc], 10)) * math.log(n / len(df[word]), 10)\n",
    "    return tf_idf, vocab, docs.keys()\n",
    "\n",
    "def cos(v1, v2):\n",
    "    if numpy.linalg.norm(v1) == 0 or numpy.linalg.norm(v2) == 0:\n",
    "        return 0\n",
    "    return numpy.dot(v1, v2) / (numpy.linalg.norm(v1) * numpy.linalg.norm(v2))\n",
    "\n",
    "\n",
    "def getVector(word, tf_idf, docs):\n",
    "    n = len(docs)\n",
    "    v = numpy.zeros(n)\n",
    "\n",
    "    for i in range(n):\n",
    "        doc = docs[i]\n",
    "        if (word, doc) in tf_idf:\n",
    "            v[i] = tf_idf[word, doc]\n",
    "\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf, vocab, docs = tf_idf_matrix(tweetDictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you were to run this against the entire data set of 9 million rows then it will take 75 hours to run. (Ex: 4000 rows take 20min to run - so - 900k rows take 75 hours which is 3 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(docs)\n",
    "name = \"Elon Musk\"\n",
    "tweets = tweetDictionary[name]\n",
    "total_words = []\n",
    "for i in range(len(tweets)):\n",
    "    if type(tweets[i]) == str:\n",
    "        words = nltk.word_tokenize(tweets[i])\n",
    "        words = [p_stemmer.stem(i) for i in words if i not in stop] #remove stopwords\n",
    "        words = [ch for ch in words if ch not in exclude]\n",
    "        for word in words:\n",
    "            if word not in total_words:\n",
    "                total_words.append(word)\n",
    "sum_words = len(total_words)\n",
    "sum_w_vec = numpy.zeros(len(docs))\n",
    "for word in total_words:\n",
    "    wordVector = getVector(word, tf_idf, docs)\n",
    "    sum_w_vec = wordVector + sum_w_vec\n",
    "doc_Cen = sum_w_vec/sum_words\n",
    "\n",
    "cosines = {}\n",
    "total_words = []\n",
    "for doc in docs:#list of names\n",
    "    tweets = tweetDictionary[doc]\n",
    "    for i in range(len(tweets)):\n",
    "        if type(tweets[i]) == str:\n",
    "            words = nltk.word_tokenize(tweets[i])\n",
    "            words = [p_stemmer.stem(i) for i in words if i not in stop] #remove stopwords\n",
    "            words = [ch for ch in words if ch not in exclude]\n",
    "            for word in words:\n",
    "                if word not in total_words:\n",
    "                    total_words.append(word)\n",
    "    word_sum = len(total_words)\n",
    "    doc_sum = numpy.zeros(len(docs))\n",
    "    for WORD in total_words:\n",
    "        v = getVector(WORD, tf_idf, docs)\n",
    "        doc_sum = doc_sum + v\n",
    "\n",
    "        centroid = doc_sum/word_sum\n",
    "        cosines[doc] = cos(doc_Cen, centroid)\n",
    "\n",
    "c2 = [(cosines[word], word) for word in cosines]\n",
    "c2.sort()\n",
    "print('\\nCEOs most similar to ' + \"''\" + name + \"''\"+ ':')\n",
    "for c, w in reversed(c2[-30:]):\n",
    "    print('   {0:<12} {1:<.6f}'.format(w, c))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=9, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "n_features = 50\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=50,\n",
    "                                stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['actually', 'air', 'amp', 'best', 'better', 'car', 'company', 'day', 'dmcryan', 'don', 'drive', 'exactly', 'fredericlambert', 'going', 'good', 'great', 'high', 'know', 'like', 'love', 'make', 'maybe', 'medium', 'model', 'month', 'need', 'new', 'people', 'point', 'production', 'really', 'right', 'soon', 'spacex', 'team', 'tesla', 'thanks', 'thing', 'think', 'time', 'true', 'uaw', 'use', 'want', 'way', 'week', 'work', 'yeah', 'year', 'yes']\n"
     ]
    }
   ],
   "source": [
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print(tf_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
       "             n_components=9, n_jobs=1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "amp work actually good high drive know make maybe year\n",
      "Topic #1:\n",
      "model spacex great love maybe production drive time air right\n",
      "Topic #2:\n",
      "tesla month drive exactly uaw true good make amp way\n",
      "Topic #3:\n",
      "production better exactly true way day point high air don\n",
      "Topic #4:\n",
      "good people fredericlambert think air year time thanks medium work\n",
      "Topic #5:\n",
      "like make time need really use going month production want\n",
      "Topic #6:\n",
      "yes year dmcryan team soon best fredericlambert going actually drive\n",
      "Topic #7:\n",
      "car don know right yeah want tesla uaw production drive\n",
      "Topic #8:\n",
      "company thanks medium uaw thing week new drive work maybe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(lda, tf_feature_names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
